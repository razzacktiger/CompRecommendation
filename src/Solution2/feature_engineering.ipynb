{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Properaty Appraisal and Comparable Recommendation System üè†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook creates a system to find the top 3 comparable properties for real estate appraisal. Given a subject property, we'll identify the most similar recently sold properties that an appraiser would use for valuation.\n",
    "\n",
    "## 1. Data Loading & Initial Setup üìä\n",
    "\n",
    "**Purpose:** Load our cleaned dataset and establish the foundation for comparable property analysis.\n",
    "\n",
    "**Appraisal Context:**\n",
    "- 9,820 sold properties that can serve as comparables\n",
    "- 88 subject properties that need appraisal\n",
    "- Goal: For each subject, find 3 best comparable sales\n",
    "\n",
    "**Comparable Selection Criteria (Industry Standard):**\n",
    "- Similar size (GLA within ¬±20%)\n",
    "- Same property type (detached, townhouse, etc.)\n",
    "- Same neighborhood/city when possible\n",
    "- Recent sales (within 90 days preferred)\n",
    "- Similar age and condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset: 7,246 potential comparable properties\n",
      "üè† 88 subject properties needing appraisal\n",
      "üìã Avg potential comps per subject: 82.3\n",
      "\n",
      "üîç Data Overview:\n",
      "   Price range: $0 - $8,775,000\n",
      "   Size range: 250 - 6930 sqft\n",
      "   Sale dates: 2024-10-16 to 2025-05-13\n"
     ]
    }
   ],
   "source": [
    "# Comparable Property Recommendation System for Appraisal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from geopy.distance import geodesic\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('data/processed/properties_deduplicated.csv')\n",
    "subjects_df = pd.read_csv('data/processed/subjects_cleaned.csv')\n",
    "\n",
    "print(f\"üìä Dataset: {df.shape[0]:,} potential comparable properties\")\n",
    "print(f\"üè† {df.subject_id.nunique()} subject properties needing appraisal\")\n",
    "print(f\"üìã Avg potential comps per subject: {df.groupby('subject_id').size().mean():.1f}\")\n",
    "\n",
    "# Basic data overview\n",
    "print(f\"\\nüîç Data Overview:\")\n",
    "print(f\"   Price range: ${df['close_price'].min():,.0f} - ${df['close_price'].max():,.0f}\")\n",
    "print(f\"   Size range: {df['gla_sqft'].min():.0f} - {df['gla_sqft'].max():.0f} sqft\")\n",
    "print(f\"   Sale dates: {df['close_date'].min()} to {df['close_date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Physical Property Similarity Features üèóÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:** Create features that measure physical similarity between subject properties and potential comparables - the foundation of appraisal methodology.\n",
    "\n",
    "**Appraisal Standards We're Following:**\n",
    "- **Size similarity**: GLA within ¬±20% is preferred, ¬±30% acceptable\n",
    "- **Bedroom/bathroom similarity**: Exact match preferred, ¬±1 acceptable  \n",
    "- **Structure type**: Must match (detached vs. townhouse affects value significantly)\n",
    "- **Age similarity**: Properties within similar age brackets\n",
    "\n",
    "**Why This Matters for Appraisal:**\n",
    "- Physical characteristics are the primary drivers of property value\n",
    "- Appraisers must justify why chosen comparables are truly \"comparable\"\n",
    "- These features will be weighted heavily in our recommendation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Creating physical similarity features for appraisal...\n",
      "‚úÖ Physical similarity features created:\n",
      "   Size excellent match (‚â§10%): 959/7,246 (13.2%)\n",
      "   Size good match (‚â§20%): 1,994/7,246 (27.5%)\n",
      "   Bedroom exact match: 2,390/7,246 (33.0%)\n",
      "   Bathroom exact match: 589/7,246 (8.1%)\n",
      "   Structure type match: 1,110/7,246 (15.3%)\n"
     ]
    }
   ],
   "source": [
    "def create_physical_similarity_features(df, subjects_df):\n",
    "    \"\"\"Create features measuring physical similarity for appraisal comparables\"\"\"\n",
    "    print(\"üèóÔ∏è Creating physical similarity features for appraisal...\")\n",
    "    \n",
    "    # Clean and prepare subject data\n",
    "    subjects_clean = subjects_df.copy()\n",
    "    \n",
    "    # Convert subject bedrooms to numeric\n",
    "    subjects_clean['bedrooms_clean'] = pd.to_numeric(subjects_clean['bedrooms_raw'], errors='coerce')\n",
    "    \n",
    "    # Parse subject bathrooms (format: \"2:1\" = 2 full + 1 half = 2.5 total)\n",
    "    def parse_bathrooms(bath_str):\n",
    "        if pd.isna(bath_str) or bath_str == '':\n",
    "            return np.nan\n",
    "        \n",
    "        bath_str = str(bath_str).strip()\n",
    "        \n",
    "        # Handle \"2:1\" format (full:half)\n",
    "        if ':' in bath_str:\n",
    "            try:\n",
    "                full, half = bath_str.split(':')\n",
    "                return float(full) + float(half) * 0.5\n",
    "            except:\n",
    "                return np.nan\n",
    "        \n",
    "        # Handle \"2F 1H\" format  \n",
    "        if 'F' in bath_str and 'H' in bath_str:\n",
    "            try:\n",
    "                parts = bath_str.replace('F', '').replace('H', '').split()\n",
    "                if len(parts) == 2:\n",
    "                    return float(parts[0]) + float(parts[1]) * 0.5\n",
    "            except:\n",
    "                return np.nan\n",
    "        \n",
    "        # Direct conversion\n",
    "        try:\n",
    "            return float(bath_str)\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    subjects_clean['bathrooms_clean'] = subjects_clean['bathrooms_raw'].apply(parse_bathrooms)\n",
    "    \n",
    "    # Merge subject characteristics with all properties\n",
    "    df_with_subjects = df.merge(\n",
    "        subjects_clean[['subject_id', 'gla_sqft', 'bedrooms_clean', 'bathrooms_clean', \n",
    "                       'structure_type', 'age_years']], \n",
    "        on='subject_id', \n",
    "        suffixes=('_prop', '_subj'),\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 1. SIZE SIMILARITY (Critical for appraisal)\n",
    "    df['gla_diff_sqft'] = abs(df_with_subjects['gla_sqft_prop'] - df_with_subjects['gla_sqft_subj'])\n",
    "    df['gla_diff_pct'] = df['gla_diff_sqft'] / df_with_subjects['gla_sqft_subj'] * 100\n",
    "    \n",
    "    # Appraisal size categories\n",
    "    df['size_match_excellent'] = (df['gla_diff_pct'] <= 10).astype(int)  # Within 10%\n",
    "    df['size_match_good'] = (df['gla_diff_pct'] <= 20).astype(int)       # Within 20%\n",
    "    df['size_match_acceptable'] = (df['gla_diff_pct'] <= 30).astype(int) # Within 30%\n",
    "    \n",
    "    # 2. BEDROOM SIMILARITY\n",
    "    df['bedroom_diff'] = abs(df['bedrooms_total'] - df_with_subjects['bedrooms_clean'])\n",
    "    df['bedroom_exact_match'] = (df['bedroom_diff'] == 0).astype(int)\n",
    "    df['bedroom_close_match'] = (df['bedroom_diff'] <= 1).astype(int)\n",
    "    \n",
    "    # 3. BATHROOM SIMILARITY  \n",
    "    df['bathroom_diff'] = abs(df['bathrooms_equivalent'] - df_with_subjects['bathrooms_clean'])\n",
    "    df['bathroom_exact_match'] = (df['bathroom_diff'] == 0).astype(int)\n",
    "    df['bathroom_close_match'] = (df['bathroom_diff'] <= 0.5).astype(int)\n",
    "    \n",
    "    # 4. STRUCTURE TYPE MATCH (Critical - must match for good comp)\n",
    "    df['structure_type_match'] = (df['structure_type'] == df_with_subjects['structure_type_subj']).astype(int)\n",
    "    \n",
    "    # 5. AGE SIMILARITY\n",
    "    df['property_age'] = 2025 - df['year_built']\n",
    "    df['age_diff_years'] = abs(df['property_age'] - df_with_subjects['age_years'])\n",
    "    df['age_similar'] = (df['age_diff_years'] <= 10).astype(int)  # Within 10 years\n",
    "    \n",
    "    print(f\"‚úÖ Physical similarity features created:\")\n",
    "    print(f\"   Size excellent match (‚â§10%): {df['size_match_excellent'].sum():,}/{len(df):,} ({df['size_match_excellent'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Size good match (‚â§20%): {df['size_match_good'].sum():,}/{len(df):,} ({df['size_match_good'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Bedroom exact match: {df['bedroom_exact_match'].sum():,}/{len(df):,} ({df['bedroom_exact_match'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Bathroom exact match: {df['bathroom_exact_match'].sum():,}/{len(df):,} ({df['bathroom_exact_match'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Structure type match: {df['structure_type_match'].sum():,}/{len(df):,} ({df['structure_type_match'].mean()*100:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the function\n",
    "df = create_physical_similarity_features(df, subjects_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Location & Proximity Features üåç\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:** Create location-based features that capture geographic proximity and market area similarity - critical for appraisal validity.\n",
    "\n",
    "**Appraisal Location Standards:**\n",
    "- **Same neighborhood preferred**: FSA (postal code area) matching\n",
    "- **Same city acceptable**: When neighborhood comps are limited\n",
    "- **Distance matters**: Closer properties are more comparable\n",
    "- **Market area consistency**: Properties should be in similar market conditions\n",
    "\n",
    "**Why Location is Critical for Appraisal:**\n",
    "- Location is the #1 factor affecting property value\n",
    "- Appraisers must justify geographic proximity of comparables\n",
    "- Different neighborhoods can have significantly different price per sqft\n",
    "- Distance adjustments may be needed for remote comparables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Creating location features for appraisal...\n",
      "‚úÖ Location features created:\n",
      "   Same city: 6,151/7,246 (84.9%)\n",
      "   Same FSA: 4,273/7,246 (59.0%)\n",
      "   Distance ‚â§1km: 2,265/7,246 (31.3%)\n",
      "   Distance ‚â§5km: 6,848/7,246 (94.5%)\n",
      "   Avg distance: 2.0km\n"
     ]
    }
   ],
   "source": [
    "def create_location_features(df, subjects_df):\n",
    "    \"\"\"Create location-based features for appraisal comparables\"\"\"\n",
    "    print(\"üåç Creating location features for appraisal...\")\n",
    "    \n",
    "    # 1. CITY/MUNICIPALITY MATCHING  \n",
    "    df['same_city'] = (df['city'] == df['city'].groupby(df['subject_id']).transform('first')).astype(int)\n",
    "    df['same_province'] = (df['state_province'] == df['state_province'].groupby(df['subject_id']).transform('first')).astype(int)\n",
    "    \n",
    "    # 2. POSTAL CODE AREA MATCHING (FSA = first 3 digits)\n",
    "    df['postal_fsa'] = df['postal_code'].str[:3]\n",
    "    df['subject_fsa'] = df['postal_fsa'].groupby(df['subject_id']).transform('first')\n",
    "    df['same_fsa'] = (df['postal_fsa'] == df['subject_fsa']).astype(int)\n",
    "    \n",
    "    # 3. DISTANCE CALCULATION\n",
    "    def calc_distance_to_subject(group):\n",
    "        if len(group) == 0:\n",
    "            return pd.Series(dtype=float)\n",
    "            \n",
    "        # Use first property as subject location proxy\n",
    "        subj_lat = group['latitude'].iloc[0]\n",
    "        subj_lon = group['longitude'].iloc[0]\n",
    "        \n",
    "        distances = []\n",
    "        for _, row in group.iterrows():\n",
    "            if pd.notna(row['latitude']) and pd.notna(row['longitude']) and \\\n",
    "               pd.notna(subj_lat) and pd.notna(subj_lon):\n",
    "                try:\n",
    "                    dist = geodesic((subj_lat, subj_lon), \n",
    "                                  (row['latitude'], row['longitude'])).kilometers\n",
    "                    distances.append(dist)\n",
    "                except:\n",
    "                    distances.append(np.nan)\n",
    "            else:\n",
    "                distances.append(np.nan)\n",
    "        \n",
    "        return pd.Series(distances, index=group.index)\n",
    "    \n",
    "    df['distance_km'] = df.groupby('subject_id').apply(calc_distance_to_subject).values\n",
    "    \n",
    "    # 4. DISTANCE CATEGORIES FOR APPRAISAL\n",
    "    df['distance_excellent'] = (df['distance_km'] <= 1).astype(int)    # Within 1km\n",
    "    df['distance_good'] = (df['distance_km'] <= 5).astype(int)         # Within 5km  \n",
    "    df['distance_acceptable'] = (df['distance_km'] <= 15).astype(int)  # Within 15km\n",
    "    \n",
    "    print(f\"‚úÖ Location features created:\")\n",
    "    print(f\"   Same city: {df['same_city'].sum():,}/{len(df):,} ({df['same_city'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Same FSA: {df['same_fsa'].sum():,}/{len(df):,} ({df['same_fsa'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Distance ‚â§1km: {df['distance_excellent'].sum():,}/{len(df):,} ({df['distance_excellent'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Distance ‚â§5km: {df['distance_good'].sum():,}/{len(df):,} ({df['distance_good'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Avg distance: {df['distance_km'].mean():.1f}km\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the function\n",
    "df = create_location_features(df, subjects_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Temporal Features ‚è∞\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:** Create features that measure how recent the comparable sales are - fresher sales are more reliable for current market valuation.\n",
    "\n",
    "**Appraisal Temporal Standards:**\n",
    "- **‚â§90 days preferred**: Most current market conditions\n",
    "- **‚â§180 days acceptable**: Still relevant for most markets\n",
    "- **>6 months**: May need market condition adjustments\n",
    "- **Sale date vs. effective date**: Compare to subject's effective date, not today\n",
    "\n",
    "**Why Recency Matters for Appraisal:**\n",
    "- Market conditions change rapidly (especially in volatile markets)\n",
    "- Appraisers prefer recent sales to reflect current market value\n",
    "- Older sales may require time adjustments\n",
    "- Seasonal effects can impact comparability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è∞ Creating temporal features for appraisal...\n",
      "‚úÖ Temporal features created:\n",
      "   Sales ‚â§90 days: 6,910/7,246 (95.4%)\n",
      "   Sales ‚â§180 days: 7,246/7,246 (100.0%)\n",
      "   Sales ‚â§1 year: 7,246/7,246 (100.0%)\n",
      "   Same season: 4,483/7,246 (61.9%)\n",
      "   Avg days from effective: 33 days\n"
     ]
    }
   ],
   "source": [
    "def create_temporal_features(df, subjects_df):\n",
    "    \"\"\"Create temporal features measuring sale recency for appraisal\"\"\"\n",
    "    print(\"‚è∞ Creating temporal features for appraisal...\")\n",
    "    \n",
    "    # Convert dates to datetime\n",
    "    df['close_date'] = pd.to_datetime(df['close_date'])\n",
    "    subjects_df['effective_date'] = pd.to_datetime(subjects_df['effective_date'])\n",
    "    \n",
    "    # Merge subject effective dates\n",
    "    df_with_subjects = df.merge(\n",
    "        subjects_df[['subject_id', 'effective_date']], \n",
    "        on='subject_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # 1. DAYS BETWEEN SALE AND APPRAISAL\n",
    "    df['days_from_effective'] = (df_with_subjects['effective_date'] - df['close_date']).dt.days\n",
    "    \n",
    "    # 2. RECENCY CATEGORIES (Appraisal Standards)\n",
    "    df['sale_very_recent'] = (df['days_from_effective'] <= 90).astype(int)    # ‚â§3 months\n",
    "    df['sale_recent'] = (df['days_from_effective'] <= 180).astype(int)        # ‚â§6 months  \n",
    "    df['sale_acceptable'] = (df['days_from_effective'] <= 365).astype(int)    # ‚â§1 year\n",
    "    \n",
    "    # 3. RECENCY SCORE (0-1, higher = more recent)\n",
    "    max_days = df['days_from_effective'].max()\n",
    "    df['recency_score'] = 1 - (df['days_from_effective'] / max_days)\n",
    "    df['recency_score'] = df['recency_score'].clip(0, 1)\n",
    "    \n",
    "    # 4. SEASONAL CONSIDERATIONS\n",
    "    df['sale_month'] = df['close_date'].dt.month\n",
    "    df['effective_month'] = df_with_subjects['effective_date'].dt.month\n",
    "    df['same_season'] = (\n",
    "        ((df['sale_month'].isin([12, 1, 2])) & (df['effective_month'].isin([12, 1, 2]))) |  # Winter\n",
    "        ((df['sale_month'].isin([3, 4, 5])) & (df['effective_month'].isin([3, 4, 5]))) |    # Spring\n",
    "        ((df['sale_month'].isin([6, 7, 8])) & (df['effective_month'].isin([6, 7, 8]))) |    # Summer\n",
    "        ((df['sale_month'].isin([9, 10, 11])) & (df['effective_month'].isin([9, 10, 11])))  # Fall\n",
    "    ).astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Temporal features created:\")\n",
    "    print(f\"   Sales ‚â§90 days: {df['sale_very_recent'].sum():,}/{len(df):,} ({df['sale_very_recent'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Sales ‚â§180 days: {df['sale_recent'].sum():,}/{len(df):,} ({df['sale_recent'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Sales ‚â§1 year: {df['sale_acceptable'].sum():,}/{len(df):,} ({df['sale_acceptable'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Same season: {df['same_season'].sum():,}/{len(df):,} ({df['same_season'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Avg days from effective: {df['days_from_effective'].mean():.0f} days\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the function\n",
    "df = create_temporal_features(df, subjects_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Market & Price Features üí∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:** Create features that capture market dynamics and price relationships - essential for understanding value patterns and market positioning.\n",
    "\n",
    "**Appraisal Market Analysis Standards:**\n",
    "- **Price per sqft comparison**: Core metric for size-adjusted value\n",
    "- **Market position**: How property compares to local market (above/below average)\n",
    "- **Price range compatibility**: Properties should be in similar value brackets\n",
    "- **Market trend awareness**: Understanding if market is rising/falling\n",
    "\n",
    "**Why Market Features Matter for Appraisal:**\n",
    "- Price per sqft is the primary adjustment metric appraisers use\n",
    "- Properties in different price tiers may not be truly comparable\n",
    "- Market trends affect how recent sales should be interpreted\n",
    "- Helps identify outliers that may not be good comparables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ Creating market & price features for appraisal...\n",
      "‚úÖ Market & price features created:\n",
      "   Price/sqft very similar (‚â§10%): 2,129/7,246 (29.4%)\n",
      "   Same market tier: 2,894/7,246 (39.9%)\n",
      "   No adjustments needed: 835/7,246 (11.5%)\n",
      "   Avg price/sqft: $513\n"
     ]
    }
   ],
   "source": [
    "def create_market_price_features(df, subjects_df):\n",
    "    \"\"\"Create market and price-based features for appraisal comparables\"\"\"\n",
    "    print(\"üí∞ Creating market & price features for appraisal...\")\n",
    "    \n",
    "    # 1. PRICE PER SQUARE FOOT ANALYSIS\n",
    "    df['price_per_sqft'] = df['close_price'] / df['gla_sqft']\n",
    "    \n",
    "    # Calculate subject estimated price per sqft (using median of similar properties)\n",
    "    def calc_subject_price_per_sqft(group):\n",
    "        # Use median price/sqft of similar sized properties as proxy\n",
    "        similar_size = group[abs(group - group.iloc[0]) <= 50]  # Within 50 $/sqft\n",
    "        if len(similar_size) > 0:\n",
    "            return similar_size.median()\n",
    "        else:\n",
    "            return group.median()\n",
    "    \n",
    "    df['subject_price_per_sqft_est'] = df.groupby('subject_id')['price_per_sqft'].transform(calc_subject_price_per_sqft)\n",
    "    \n",
    "    # 2. PRICE PER SQFT SIMILARITY\n",
    "    df['price_per_sqft_diff'] = abs(df['price_per_sqft'] - df['subject_price_per_sqft_est'])\n",
    "    df['price_per_sqft_diff_pct'] = (df['price_per_sqft_diff'] / df['subject_price_per_sqft_est']) * 100\n",
    "    \n",
    "    # Price per sqft categories\n",
    "    df['price_psf_very_similar'] = (df['price_per_sqft_diff_pct'] <= 10).astype(int)  # Within 10%\n",
    "    df['price_psf_similar'] = (df['price_per_sqft_diff_pct'] <= 20).astype(int)       # Within 20%\n",
    "    df['price_psf_acceptable'] = (df['price_per_sqft_diff_pct'] <= 30).astype(int)    # Within 30%\n",
    "    \n",
    "    # 3. MARKET POSITION FEATURES\n",
    "    # Calculate market percentiles by city\n",
    "    df['city_price_percentile'] = df.groupby('city')['close_price'].rank(pct=True)\n",
    "    df['city_psf_percentile'] = df.groupby('city')['price_per_sqft'].rank(pct=True)\n",
    "    \n",
    "    # Market tier classification\n",
    "    df['market_tier'] = pd.cut(df['city_price_percentile'], \n",
    "                              bins=[0, 0.33, 0.67, 1.0], \n",
    "                              labels=['Lower', 'Middle', 'Upper'])\n",
    "    \n",
    "    # Same market tier as subject\n",
    "    df['subject_market_tier'] = df.groupby('subject_id')['market_tier'].transform('first')\n",
    "    df['same_market_tier'] = (df['market_tier'] == df['subject_market_tier']).astype(int)\n",
    "    \n",
    "    # 4. VALUE ADJUSTMENT INDICATORS\n",
    "    df['needs_size_adjustment'] = (df['gla_diff_pct'] > 10).astype(int)\n",
    "    df['needs_location_adjustment'] = (df['same_city'] == 0).astype(int)\n",
    "    df['needs_time_adjustment'] = (df['days_from_effective'] > 90).astype(int)\n",
    "    \n",
    "    # Total adjustments needed (fewer is better for comparables)\n",
    "    df['total_adjustments_needed'] = (df['needs_size_adjustment'] + \n",
    "                                     df['needs_location_adjustment'] + \n",
    "                                     df['needs_time_adjustment'])\n",
    "    \n",
    "    print(f\"‚úÖ Market & price features created:\")\n",
    "    print(f\"   Price/sqft very similar (‚â§10%): {df['price_psf_very_similar'].sum():,}/{len(df):,} ({df['price_psf_very_similar'].mean()*100:.1f}%)\")\n",
    "    print(f\"   Same market tier: {df['same_market_tier'].sum():,}/{len(df):,} ({df['same_market_tier'].mean()*100:.1f}%)\")\n",
    "    print(f\"   No adjustments needed: {(df['total_adjustments_needed'] == 0).sum():,}/{len(df):,} ({(df['total_adjustments_needed'] == 0).mean()*100:.1f}%)\")\n",
    "    print(f\"   Avg price/sqft: ${df['price_per_sqft'].mean():.0f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the function\n",
    "df = create_market_price_features(df, subjects_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Composite Comparable Score & Ranking üéØ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:** Create a comprehensive scoring system that combines all similarity features to rank potential comparables - mimicking how appraisers evaluate and select the best comparables.\n",
    "\n",
    "**Appraisal Scoring Methodology:**\n",
    "- **Physical similarity (40%)**: Size, bedrooms, bathrooms, structure type\n",
    "- **Location proximity (30%)**: Distance, same neighborhood/city\n",
    "- **Temporal recency (20%)**: How recent the sale is\n",
    "- **Market compatibility (10%)**: Price range and market tier alignment\n",
    "\n",
    "**Final Output:**\n",
    "- Composite score (0-100) for each potential comparable\n",
    "- Ranking within each subject property group\n",
    "- Top 3 recommendations per subject (ready for appraisal use)\n",
    "- Quality flags for exceptional vs. marginal comparables\n",
    "\n",
    "**Why This Matters:**\n",
    "- Provides objective, defensible comparable selection\n",
    "- Ensures consistency across different appraisers\n",
    "- Identifies when comparable supply is limited (quality warnings)\n",
    "- Creates audit trail for appraisal review process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Creating composite comparable scoring system...\n",
      "‚úÖ Composite scoring completed:\n",
      "   Excellent comparables (‚â•80): 704 (9.7%)\n",
      "   Good comparables (‚â•60): 2,298 (31.7%)\n",
      "   Top 3 selections: 449 total recommendations\n",
      "   Avg composite score: 57.6\n",
      "\n",
      "üìä Top 3 Comparable Quality Distribution:\n",
      "   Excellent: 322 (71.7%)\n",
      "   Good: 95 (21.2%)\n",
      "   Fair: 32 (7.1%)\n"
     ]
    }
   ],
   "source": [
    "def create_composite_comparable_score(df):\n",
    "    \"\"\"Create comprehensive scoring system for comparable property ranking\"\"\"\n",
    "    print(\"üéØ Creating composite comparable scoring system...\")\n",
    "    \n",
    "    # WEIGHT CONFIGURATION (Based on Appraisal Standards)\n",
    "    weights = {\n",
    "        'physical': 0.40,    # Size, bedrooms, bathrooms, structure type\n",
    "        'location': 0.30,    # Distance, same neighborhood/city  \n",
    "        'temporal': 0.20,    # Sale recency\n",
    "        'market': 0.10       # Price compatibility, market tier\n",
    "    }\n",
    "    \n",
    "    # 1. PHYSICAL SIMILARITY SCORE (0-100)\n",
    "    physical_score = (\n",
    "        df['size_match_excellent'] * 30 +           # Perfect size match\n",
    "        df['size_match_good'] * 20 +                # Good size match\n",
    "        df['size_match_acceptable'] * 10 +          # Acceptable size match\n",
    "        df['bedroom_exact_match'] * 25 +            # Bedroom match\n",
    "        df['bathroom_exact_match'] * 15 +           # Bathroom match\n",
    "        df['structure_type_match'] * 30 +           # Structure type (critical)\n",
    "        df['age_similar'] * 10                      # Age similarity\n",
    "    )\n",
    "    df['physical_score'] = physical_score.clip(0, 100)\n",
    "    \n",
    "    # 2. LOCATION PROXIMITY SCORE (0-100)\n",
    "    location_score = (\n",
    "        df['same_fsa'] * 40 +                       # Same postal area (best)\n",
    "        df['same_city'] * 25 +                      # Same city\n",
    "        df['distance_excellent'] * 30 +            # Within 1km\n",
    "        df['distance_good'] * 15 +                  # Within 5km\n",
    "        df['distance_acceptable'] * 5               # Within 15km\n",
    "    )\n",
    "    df['location_score'] = location_score.clip(0, 100)\n",
    "    \n",
    "    # 3. TEMPORAL RECENCY SCORE (0-100)\n",
    "    temporal_score = (\n",
    "        df['sale_very_recent'] * 50 +               # ‚â§90 days (preferred)\n",
    "        df['sale_recent'] * 30 +                    # ‚â§180 days\n",
    "        df['sale_acceptable'] * 15 +                # ‚â§1 year\n",
    "        df['same_season'] * 20 +                    # Seasonal consistency\n",
    "        df['recency_score'] * 30                    # Continuous recency score\n",
    "    )\n",
    "    df['temporal_score'] = temporal_score.clip(0, 100)\n",
    "    \n",
    "    # 4. MARKET COMPATIBILITY SCORE (0-100)\n",
    "    market_score = (\n",
    "        df['price_psf_very_similar'] * 40 +         # Price/sqft very similar\n",
    "        df['price_psf_similar'] * 25 +              # Price/sqft similar\n",
    "        df['price_psf_acceptable'] * 15 +           # Price/sqft acceptable\n",
    "        df['same_market_tier'] * 30 +               # Same market tier\n",
    "        (3 - df['total_adjustments_needed']) * 10   # Fewer adjustments needed\n",
    "    )\n",
    "    df['market_score'] = market_score.clip(0, 100)\n",
    "    \n",
    "    # 5. COMPOSITE SCORE (Weighted Average)\n",
    "    df['composite_score'] = (\n",
    "        df['physical_score'] * weights['physical'] +\n",
    "        df['location_score'] * weights['location'] +\n",
    "        df['temporal_score'] * weights['temporal'] +\n",
    "        df['market_score'] * weights['market']\n",
    "    )\n",
    "    \n",
    "    # 6. RANKING WITHIN EACH SUBJECT\n",
    "    df['comparable_rank'] = df.groupby('subject_id')['composite_score'].rank(\n",
    "        method='dense', ascending=False\n",
    "    ).astype(int)\n",
    "    \n",
    "    # 7. QUALITY CLASSIFICATION\n",
    "    def classify_comparable_quality(score):\n",
    "        if score >= 80:\n",
    "            return 'Excellent'\n",
    "        elif score >= 60:\n",
    "            return 'Good'\n",
    "        elif score >= 40:\n",
    "            return 'Fair'\n",
    "        else:\n",
    "            return 'Poor'\n",
    "    \n",
    "    df['comparable_quality'] = df['composite_score'].apply(classify_comparable_quality)\n",
    "    \n",
    "    # 8. TOP 3 RECOMMENDATIONS PER SUBJECT\n",
    "    df['is_top3_comparable'] = (df['comparable_rank'] <= 3).astype(int)\n",
    "    \n",
    "    print(f\"‚úÖ Composite scoring completed:\")\n",
    "    print(f\"   Excellent comparables (‚â•80): {(df['comparable_quality'] == 'Excellent').sum():,} ({(df['comparable_quality'] == 'Excellent').mean()*100:.1f}%)\")\n",
    "    print(f\"   Good comparables (‚â•60): {(df['comparable_quality'] == 'Good').sum():,} ({(df['comparable_quality'] == 'Good').mean()*100:.1f}%)\")\n",
    "    print(f\"   Top 3 selections: {df['is_top3_comparable'].sum():,} total recommendations\")\n",
    "    print(f\"   Avg composite score: {df['composite_score'].mean():.1f}\")\n",
    "    \n",
    "    # Quality check per subject\n",
    "    top3_quality = df[df['is_top3_comparable'] == 1]['comparable_quality'].value_counts()\n",
    "    print(f\"\\nüìä Top 3 Comparable Quality Distribution:\")\n",
    "    for quality, count in top3_quality.items():\n",
    "        print(f\"   {quality}: {count} ({count/df['is_top3_comparable'].sum()*100:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the function\n",
    "df = create_composite_comparable_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß FIXING TOP 3 RECOMMENDATIONS WITH PROPER TIE-BREAKING\n",
      "============================================================\n",
      "üìä CURRENT ISSUE ANALYSIS:\n",
      "   Recommendations per subject distribution:\n",
      "   3     33\n",
      "4     19\n",
      "5     12\n",
      "6     12\n",
      "7      3\n",
      "8      1\n",
      "10     1\n",
      "11     1\n",
      "12     1\n",
      "13     2\n",
      "16     1\n",
      "17     1\n",
      "21     1\n",
      "Name: count, dtype: int64\n",
      "   Subjects with exactly 3 recommendations: 33/88\n",
      "\n",
      "üîÑ APPLYING PROPER RANKING...\n",
      "\n",
      "‚úÖ FIXED RESULTS:\n",
      "   Recommendations per subject distribution:\n",
      "   3    88\n",
      "Name: count, dtype: int64\n",
      "   Subjects with exactly 3 recommendations: 88/88\n",
      "\n",
      "üìä FINAL SUMMARY:\n",
      "   Total properties: 7,246\n",
      "   Total top 3 recommendations: 264\n",
      "   Average composite score of top 3: 81.4\n",
      "\n",
      "üèÜ FIXED TOP 3 QUALITY DISTRIBUTION:\n",
      "   Excellent: 169 (64.0%)\n",
      "   Good: 71 (26.9%)\n",
      "   Fair: 24 (9.1%)\n",
      "\n",
      "üíæ READY TO SAVE:\n",
      "   ‚Ä¢ Fixed dataset: 7,246 rows √ó 92 columns\n",
      "   ‚Ä¢ Fixed top 3 recommendations: 264 rows\n"
     ]
    }
   ],
   "source": [
    "# ## 8. Fix Top 3 Recommendations (Proper Tie-Breaking) üîß\n",
    "\n",
    "# **Purpose:** Fix the ranking issue where ties in composite scores caused some subjects to have more or fewer than 3 recommendations.\n",
    "# \n",
    "# **Problem:** When multiple properties had identical composite scores, they all received the same rank, causing inconsistent top 3 selections.\n",
    "# \n",
    "# **Solution:** Implement proper tie-breaking using secondary criteria (distance, recency) to ensure exactly 3 recommendations per subject.\n",
    "\n",
    "print(\"üîß FIXING TOP 3 RECOMMENDATIONS WITH PROPER TIE-BREAKING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Current issue analysis\n",
    "current_top3_counts = df[df['is_top3_comparable'] == 1].groupby('subject_id').size()\n",
    "print(f\"üìä CURRENT ISSUE ANALYSIS:\")\n",
    "print(f\"   Recommendations per subject distribution:\")\n",
    "print(f\"   {current_top3_counts.value_counts().sort_index()}\")\n",
    "print(f\"   Subjects with exactly 3 recommendations: {(current_top3_counts == 3).sum()}/{len(current_top3_counts)}\")\n",
    "\n",
    "# Fix ranking with proper tie-breaking\n",
    "def rank_comparables_properly(group):\n",
    "    \"\"\"Rank comparables with proper tie-breaking using multiple criteria\"\"\"\n",
    "    # Sort by:\n",
    "    # 1. Composite score (descending - higher is better)\n",
    "    # 2. Distance (ascending - closer is better) \n",
    "    # 3. Recency score (descending - more recent is better)\n",
    "    # 4. Property ID (ascending - for final tie-breaking)\n",
    "    group_sorted = group.sort_values([\n",
    "        'composite_score', \n",
    "        'distance_km', \n",
    "        'recency_score',\n",
    "        'property_id'\n",
    "    ], ascending=[False, True, False, True])\n",
    "    \n",
    "    # Assign sequential ranks (1, 2, 3, ...)\n",
    "    group_sorted['comparable_rank_fixed'] = range(1, len(group_sorted) + 1)\n",
    "    \n",
    "    return group_sorted\n",
    "\n",
    "print(f\"\\nüîÑ APPLYING PROPER RANKING...\")\n",
    "\n",
    "# Apply proper ranking to each subject group\n",
    "df_fixed = df.groupby('subject_id').apply(rank_comparables_properly).reset_index(drop=True)\n",
    "\n",
    "# Create new top 3 flag with fixed ranking\n",
    "df_fixed['is_top3_comparable_fixed'] = (df_fixed['comparable_rank_fixed'] <= 3).astype(int)\n",
    "\n",
    "# Verify the fix\n",
    "fixed_top3_counts = df_fixed[df_fixed['is_top3_comparable_fixed'] == 1].groupby('subject_id').size()\n",
    "\n",
    "print(f\"\\n‚úÖ FIXED RESULTS:\")\n",
    "print(f\"   Recommendations per subject distribution:\")\n",
    "print(f\"   {fixed_top3_counts.value_counts().sort_index()}\")\n",
    "print(f\"   Subjects with exactly 3 recommendations: {(fixed_top3_counts == 3).sum()}/{len(fixed_top3_counts)}\")\n",
    "\n",
    "# Handle edge cases (subjects with < 3 available properties)\n",
    "subjects_with_few_props = fixed_top3_counts[fixed_top3_counts < 3]\n",
    "if len(subjects_with_few_props) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  EDGE CASES - Subjects with < 3 available properties:\")\n",
    "    for subject_id, count in subjects_with_few_props.items():\n",
    "        total_available = len(df_fixed[df_fixed['subject_id'] == subject_id])\n",
    "        print(f\"   Subject {subject_id}: {count} recommendations (only {total_available} properties available)\")\n",
    "\n",
    "# Update the main dataframe\n",
    "df = df_fixed.copy()\n",
    "\n",
    "# Create clean top 3 dataset\n",
    "top3_comparables_fixed = df[df['is_top3_comparable_fixed'] == 1].copy()\n",
    "\n",
    "print(f\"\\nüìä FINAL SUMMARY:\")\n",
    "print(f\"   Total properties: {len(df):,}\")\n",
    "print(f\"   Total top 3 recommendations: {len(top3_comparables_fixed):,}\")\n",
    "print(f\"   Average composite score of top 3: {top3_comparables_fixed['composite_score'].mean():.1f}\")\n",
    "\n",
    "# Quality distribution of fixed top 3\n",
    "print(f\"\\nüèÜ FIXED TOP 3 QUALITY DISTRIBUTION:\")\n",
    "quality_dist_fixed = top3_comparables_fixed['comparable_quality'].value_counts()\n",
    "for quality in ['Excellent', 'Good', 'Fair', 'Poor']:\n",
    "    if quality in quality_dist_fixed.index:\n",
    "        count = quality_dist_fixed[quality]\n",
    "        pct = count / len(top3_comparables_fixed) * 100\n",
    "        print(f\"   {quality}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüíæ READY TO SAVE:\")\n",
    "print(f\"   ‚Ä¢ Fixed dataset: {len(df):,} rows √ó {len(df.columns)} columns\")\n",
    "print(f\"   ‚Ä¢ Fixed top 3 recommendations: {len(top3_comparables_fixed):,} rows\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Engineered Dataset & Summary üíæ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:** Save the fully engineered dataset and provide a comprehensive summary of our comparable recommendation system.\n",
    "\n",
    "**What We've Built:**\n",
    "- Complete feature engineering for appraisal-grade comparable selection\n",
    "- 40+ engineered features covering physical, location, temporal, and market similarity\n",
    "- Composite scoring system with industry-standard weighting\n",
    "- Top 3 comparable recommendations per subject property\n",
    "\n",
    "**Dataset Output:**\n",
    "- Ready for statistical analysis or machine learning model training\n",
    "- Each row represents a potential comparable with full similarity scoring\n",
    "- Top 3 recommendations clearly flagged for immediate appraisal use\n",
    "- Quality classifications for risk assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saving engineered dataset...\n",
      "‚úÖ Datasets saved:\n",
      "   Complete dataset: 7,246 rows √ó 92 columns\n",
      "   Top 3 recommendations: 449 rows\n",
      "\n",
      "üè† COMPARABLE RECOMMENDATION SYSTEM SUMMARY\n",
      "============================================================\n",
      "\n",
      "üìä DATASET OVERVIEW:\n",
      "   ‚Ä¢ 88 subject properties analyzed\n",
      "   ‚Ä¢ 7,246 potential comparable properties\n",
      "   ‚Ä¢ 92 total features engineered\n",
      "   ‚Ä¢ 449 top recommendations selected\n",
      "\n",
      "üéØ FEATURE ENGINEERING RESULTS:\n",
      "   Physical Similarity:\n",
      "     - Size excellent match: 13.2%\n",
      "     - Structure type match: 15.3%\n",
      "     - Bedroom exact match: 33.0%\n",
      "   Location Proximity:\n",
      "     - Same city: 84.9%\n",
      "     - Same FSA: 59.0%\n",
      "     - Within 1km: 31.3%\n",
      "   Temporal Recency:\n",
      "     - Sales ‚â§90 days: 95.4%\n",
      "     - Sales ‚â§180 days: 100.0%\n",
      "   Market Compatibility:\n",
      "     - Price/sqft similar: 49.7%\n",
      "     - Same market tier: 39.9%\n",
      "\n",
      "üèÜ RECOMMENDATION QUALITY:\n",
      "   Excellent: 9.7%\n",
      "   Good: 31.7%\n",
      "   Fair: 44.2%\n",
      "   Poor: 14.4%\n",
      "\n",
      "üìà TOP 3 RECOMMENDATIONS PER SUBJECT:\n",
      "   Average score of top 3: 83.3\n",
      "   Subjects with 3 excellent comps: 8/88\n",
      "   Subjects with 0 excellent comps: 23/88\n",
      "\n",
      "‚úÖ SYSTEM READY FOR:\n",
      "   ‚Ä¢ Statistical comparable analysis\n",
      "   ‚Ä¢ Machine learning model training\n",
      "   ‚Ä¢ Direct appraisal use (top 3 recommendations)\n",
      "   ‚Ä¢ Automated valuation model (AVM) development\n",
      "\n",
      "üìÅ OUTPUT FILES:\n",
      "   ‚Ä¢ properties_with_comparison_engineered.csv (complete dataset)\n",
      "   ‚Ä¢ top3_comparable_recommendations.csv (appraisal-ready)\n"
     ]
    }
   ],
   "source": [
    "# Save the fully engineered dataset\n",
    "print(\"üíæ Saving engineered dataset...\")\n",
    "\n",
    "# Save complete dataset with all features\n",
    "df.to_csv('data/processed/properties_comparison_engineered.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
